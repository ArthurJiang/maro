{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy Policy\n",
    "\n",
    "In this notebook, we demonstrate using a simple greedy policy for Citi Bike, a real-world bike repositioning scenario. For detailed information about the scenario, refer to https://maro.readthedocs.io/en/latest/scenarios/container_inventory_management.html. Our greedy policy is simple: if the event type is supply, the policy has the current station send as many bikes as possible to one of k stations with the most empty slots. If the event type is demand, the policy has the current station request as many bikes as possible from one of k stations with the most bikes. We use a heap data structure to find the top k supply/demand candidates from the action scope associated with each decision event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import heapq\n",
    "import random\n",
    "\n",
    "from maro.simulator import Env\n",
    "from maro.simulator.scenarios.citi_bike.common import Action, DecisionEvent, DecisionType\n",
    "\n",
    "\n",
    "class GreedyPolicy:\n",
    "    def __init__(self, supply_top_k: int = 1, demand_top_k: int = 1):\n",
    "        self._supply_top_k = supply_top_k\n",
    "        self._demand_top_k = demand_top_k\n",
    "\n",
    "    def choose_action(self, decision_event: DecisionEvent):\n",
    "        if decision_event.type == DecisionType.Supply:\n",
    "            # Find k target stations with the most empty slots, randomly choose one of them and send as many bikes to\n",
    "            # it as allowed by the action scope.\n",
    "            top_k_demands = []\n",
    "            for demand_candidate, available_docks in decision_event.action_scope.items():\n",
    "                if demand_candidate == decision_event.station_idx:\n",
    "                    continue\n",
    "\n",
    "                heapq.heappush(top_k_demands, (available_docks, demand_candidate))\n",
    "                if len(top_k_demands) > self._demand_top_k:\n",
    "                    heapq.heappop(top_k_demands)\n",
    "\n",
    "            max_reposition, target_station_idx = random.choice(top_k_demands)\n",
    "            action = Action(decision_event.station_idx, target_station_idx, max_reposition)\n",
    "        else:\n",
    "            # Find k source stations with the most bikes, randomly choose one of them and request as many bikes from\n",
    "            # it as allowed by the action scope.\n",
    "            top_k_supplies = []\n",
    "            for supply_candidate, available_bikes in decision_event.action_scope.items():\n",
    "                if supply_candidate == decision_event.station_idx:\n",
    "                    continue\n",
    "\n",
    "                heapq.heappush(top_k_supplies, (available_bikes, supply_candidate))\n",
    "                if len(top_k_supplies) > self._supply_top_k:\n",
    "                    heapq.heappop(top_k_supplies)\n",
    "\n",
    "            max_reposition, source_idx = random.choice(top_k_supplies)\n",
    "            action = Action(source_idx, decision_event.station_idx, max_reposition)\n",
    "\n",
    "        return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation with the Greedy Policy\n",
    "\n",
    "The scenario data was based on true data logged by Citi Bike during the first 2 days (2880 minutes) of January, 2018. Note that only one episode is needed because we are not actually doing any learning here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(scenario=\"citi_bike\", topology=\"ny.201801\", start_tick=0, durations=2880, snapshot_resolution=10)\n",
    "policy = GreedyPolicy()\n",
    "metrics, decision_event, done = env.step(None)\n",
    "while not done:\n",
    "    metrics, decision_event, done = env.step(policy.choose_action(decision_event))\n",
    "\n",
    "print(f\"Greedy policy performance: {env.metrics}\")\n",
    "env.reset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
